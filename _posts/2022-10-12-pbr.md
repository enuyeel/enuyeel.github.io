---
layout: post
title: "Physically Based Rendering (WIP)"
permalink: /blog/:year/:month/:day/:title
---

The brightness of a surface is defined as its surface radiance. How do you then go about measuring the brightness of a surface? <br>
Imagine a sensor of some area at a distance to the surface of interest. If you move the sensor further away from the surface, you can intuitively tell it will receive less light. More formally, it's due to the solid angle $$\omega$$ with respect to each point on the surface decreasing. In other words, it's the area of the sensor staying the same, but the distance (radius of the sphere/hemisphere) between the sensor and the point on the surface increases. The solid angle $$\omega$$ is defined as the area $$A$$ over the radius squared $$r^2$$. <br>

$$\omega=\frac{A}{r^2}$$

By definition, it's inversely proportional to the radius squared $$r^2$$, and it's only the radius $$r$$ increasing in this scenario, hence the smaller solid angle $$\omega$$. <br>
If you increase the area of the surface, on the other hand, more light will enter the sensor, therefore increasing the perceived brightness.<br>
Therefore, when you define the brightness of a surface, you need to normalize with respect to both the area of the surface as well as the solid angle subtended by each point in the surface with respect to your sensor. <br>
This brings us to the definition that surface radiance $$L$$ is defined as flux $$\Phi$$ per unit (foreshortened) area $$dAcos\theta_{r}$$ per unit solid angle $$d\omega$$. It’s good to be reminded now that the surface radiance $$L$$ depends on the reflectance properties of a surface, which I’ll go more in-depth about later in the article. <br>

$$L=\frac{d^2\Phi}{(dAcos\theta_{r})d\omega}$$

Don't let the complex Mathematical notation throw you off, though! If we consider the solid angle $$\omega$$ and the area $$A$$ to be infinitesimal, we can effectively translate the surface to a single point (or fragment) and the solid angle into a directional vector (from a fragment to one of the points on the hemisphere's curved surface). Although the actual implementations won't closely resemble the above formula, this radiometry concept is the backbone of Physically Based Rendering (PBR), and many different models describing the way that light scatters at surfaces are somewhat directly and indirectly derived from it. <br>
<br>\*\*\*<br><br>
It is to be noted that a single point on the surface at the macro level can be modeled as a collection of small microfacets at the micro level, hence the coin of the term Microfacet Model, and it's their aggregate behavior against the light that determines the observed light scattering. <br>
It is our interest how not just a single, but every microfacet on a differential area (a fragment) scatters any incoming lights in all different directions (technically only the directions covered by the upper hemisphere), thus a need for integrating the surface response over a hemisphere. <br>
Although we can assume that a single incoming light will hit off every microfacet within the hemisphere at the same incident angle, it is still computationally heavy to calculate integration for every shaded fragment (multiple integrations if the scene consists of more than one light source). It’s best if our surface response which consists of diffuse and specular components can effectively be boiled down to a statistical approximation. <br>
For a refresher, the moment a light ray hits a surface, it gets split into both reflection and refraction parts. Reflection is when a light ray doesn’t enter the surface and gets directly reflected, while refraction is when a light ray enters the surface and either gets absorbed or later emerges from the surface at a distance. The reflection part corresponds to the specular component, while the refraction part translates to the diffuse component. It should be mentioned that conductors (e.g purely metallic materials) have no diffuse component. <br>
There are many different versions of general microfacet model equations available online. It should be noted that since my PBR implementation for the most part is based on Google Filament, I'll borrow their notations from now on unless otherwise specified. <br>
<br>\*\*\*<br><br>
This is an excerpt from [Nayar21a]:
  "There are two directions that are important to us. One is the direction from which the light arrives, and the second is the direction in which light is being reflected and observed. So, to represent the reflectance properties of any material, we want to be able to describe its properties both in terms of the illumination direction and the viewing direction of the reflection direction. So, that brings us to the Bidirectional Reflectance Distribution Function."<br>
BRDF is a 4-dimensional function that takes in 2 sets of zenith and azimuth angles, where each set represents the incoming light and the outgoing viewing direction. <br>

$$f(\theta_i,\phi_i,\theta_r,\phi_r)$$

Often its parameterization is simplified with the said two vectors accordingly. It then describes the reflectance properties of a surface, or in layman's terms, surface response. <br>
The complete surface response BRDF can then be expressed as a combination of two individual BRDF terms as such:<br>

$$f(v,l)=f_d(v,l)+f_r(v,l)$$

Each of $$f_d$$ and $$f_r$$ represents the diffuse component and the specular component correspondingly, and we'll first look into the specular BRDF term $$f_r$$. <br>

$$f_r(v,l)=\frac{D(h,\alpha)G(v,l,\alpha)F(v,h,f0)}{4(n\cdot v)(n\cdot l)}$$

There’s seemingly a lot to digest here, but this form of BRDF is generally known as the Torrance-Sparrow model. A little bit of everything is involved in the derivation of this formula, notably, the definition of surface radiance and BRDF. If one’s eager to check out, [Humphreys18] has always been my go-to reference.<br>
Each of the three different terms on the numerator has its specific role for this BRDF. Before I go over them individually, it should be mentioned that the derivation itself depends on neither the particular $$D$$ term (normal distribution function) nor a particular $$F$$ term (Fresnel function), which means we can pretty much swap those terms in and out with whatever valid combinations we have. $$G$$ (Smith geometric shadowing function) on the other hand depends on its counterpart $$D$$ function, and its derivation is well documented in [Heitz14]. <br>
<br>\*\*\*<br><br>
[Walter07] suggests that the (normalized) normal distribution function $$D(m)$$ should give the differential area of microfacets aligned with the directional vector $$m$$ (denoted $$dA_{m}$$) when multiplied with a couple of terms, which are as follows:<br>
(1) an infinitesimal solid angle centered on $$m$$ (denoted $$d\omega_{m}$$, which are if loosely spoken, a set of directions near $$m$$ according to [Reed13]),<br>
(2) a macrosurface $$dA$$ (beneath microfacets).<br>
It is to be noted that $$D(m)$$ is an abbreviated version of $$D(m, \alpha)$$, where $$\alpha$$ denotes the roughness parameter. Also, to avoid further confusion, it’d be appropriate to replace $$m$$ with half vector $$h$$ if possible from this point and on.<br>

$$dA_{h}=D(h,\alpha)d\omega_{h}dA\hspace{1mm}$$

Following is a list of properties any plausible $$D(m)$$ should obey, extracted from the same paper and slightly modified for consistency in notation:<br>

$$0\leq D(h,\alpha)\leq \infty\hspace{1mm} \cdots (1)$$

$$1\leq \int_{\Omega}^{}D(h,\alpha)d\omega_{h}\hspace{1mm} \cdots (2)$$

$$(v\cdot n)=\int_{\Omega}^{}D(h,\alpha)(v\cdot h)d\omega_{h}\hspace{1mm}\cdots(3.1)$$

$$1=\int_{\Omega}^{}D(h,\alpha)(n\cdot h)d\omega_{h}\hspace{1mm}\cdots(3.2)$$

I have to admit that was a bit harsh opener for a new section. So, what exactly is the NDF again? If were to gloss over all the nitty gritty details, it’s a weighting function for scaling the highlight of specular reflection in BRDF.<br>
In its normalized form, NDF is a probability density function (PDF, in short). PDF has the property of being non-negative everywhere, and at the same time, the area under its curve sums up to $$1$$. Due to the aforementioned properties, $$D(h,\alpha)$$ is designed to shoot up much higher than $$1$$ (hence, probability density, not probability) in a scenario where the surface is smooth (lower $$\alpha$$ value) and the half vector $$h$$ is close to the macrosurface normal $$n$$. Property $$(1)$$ implies this very characteristic.<br>
Property $$(2)$$ on the other hand, suggests that given a perfectly smooth macrosurface of an area of size $$1$$, just any microfacets heightfield (correlated or not correlated) imaginable laying on top of it will surely yield a total area of size greater than or equal to $$1$$. ~~It might be a stretch, but it might even be possible to yield a $$dA_{h}$$ of size much greater than $$1$$ if we imagine a macrosurface punctured with a bunch of infinitely small needles, overall resembling a dense forest.~~<br>
The last property $$(3.1)$$ brings up the point that the area of the microfacets aligned with $$h$$ ($$dA_{h}$$) projected to given direction $$v$$ equals the area of the macrosurface projected to the same vector when integrated over the hemisphere. $$(3.2)$$ is a special case when $$v=n$$, and is an important property that has been extensively covered in [Reed13]. It suggests that by making certain that the area of the microfacets projected directly downward (projected to $$n$$) equals the area of the macrosurface beneath them, (in other words, normalizing) it ensures the physical plausibility of the BRDF. [Humphreys18] provides a great visualization of this concept [**here**](https://www.pbr-book.org/3ed-2018/Reflection_Models/Microfacet_Models#fig:microfacet-projected-area).<br>
So, yet again, what exactly is the NDF? It’s easier to go over its properties, but it surely is difficult to pin down its definition. Here is a list of definitions suggested by a couple of scholars, and you can choose whatever suits your liking!<br>
According to [Hoffman15]:
  "The NDF gives the concentration of microfacet normals pointing in a given direction (in this case, the half-angle direction), relative to surface area. The NDF determines the size and shape of the highlight." (p. 71)<br>
According to [Walter07]:
  "The microfacet normal distribution, $$D(m)$$, describes the statistical distribution of surface normals $$m$$ over the microsurface." (p. 3)<br>
It is finally about time to introduce an actual NDF! One can easily come across many different versions of NDF online, but I’ll be introducing the isotropic version of the Trowbridge-Reitz (GGX) distribution in this article.<br>

$$D(h,\alpha)=\frac{\alpha^2}{\pi((n\cdot h)^2(\alpha^2-1)+1)^2}$$

You can easily check out that this normalized NDF does indeed yield $$1$$ when integrated over the hemisphere (Recall the property $$(3.2)$$). Below is the slightly rephrased formula for the purpose of feeding into a computer algebra system (CAS), and my go-to choice has always been Desmos! It should be noted that the outermost integration over the azimuth angle $$\phi$$ has been replaced with multiplication by $$2\pi$$, to take into account that the isotropic version of NDF only depends on zenith angle $$\theta$$.<br>

$$D(\theta,\alpha)=\frac{\alpha^2}{\pi(cos^2(\theta)(\alpha^2-1)+1)^2}$$

$$2\pi\int_{0}^{2\pi}D(\theta,\alpha)cos(\theta)sin(\theta)d\theta=1$$

<br>\*\*\*<br><br>



You can check out the different shapes of NDFs [**here**](https://www.desmos.com/calculator/ewcjfzvfnk), and play around with them to figure out which would be the fittest for your application. <br>

<br>

**Bibliograph**<br>
[[**Heitz14**]](https://jcgt.org/published/0003/02/03/paper.pdf) Eric Heitz. 2014. Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs.
[[**Walter07**]](https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.html) Bruce Walter et el. 2007. Microfacet Models for Refraction through Rough Surfaces.
[[**Reed13**]](https://www.reedbeta.com/blog/hows-the-ndf-really-defined/) Nathan Reed. 2013. How Is The NDF Really Defined?. https://www.reedbeta.com/blog/hows-the-ndf-really-defined/
[[**Hoffman15**]](https://blog.selfshadow.com/publications/s2015-shading-course/hoffman/s2015_pbs_physics_math_slides.pdf) Naty Hoffman. 2015. Physics and Math of Shading. https://blog.selfshadow.com/publications/s2015-shading-course/hoffman/s2015_pbs_physics_math_slides.pdf
[[**Nayar21a**]](https://youtu.be/R9iZzaXUaK4) Shree K. Nayar. 2021. BRDF: Bidirectional Reflectance Distribution Function. https://youtu.be/R9iZzaXUaK4
[[**Nayar21b**]](https://youtu.be/tflz0loWhIY) Shree K. Nayar. 2021. Radiometric Concepts | Radiometry and Reflectance. https://youtu.be/R9iZzaXUaK4
[[**Humphreys18**]](https://www.pbr-book.org/) Greg Humphreys et el. 2018. Physically Based Rendering:From Theory To Implementation. https://www.pbr-book.org/
[[**Karis13**]](http://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html) Brian Karis. 2013. Specular BRDF Reference. http://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html

- [Google Filament Documentation](https://google.github.io/filament/Filament.html)
- [Google Filament shading_model_standard.fs](https://google.github.io/filament/Filament.html)
- [Google Filament brdf.fs](https://github.com/google/filament/blob/main/shaders/src/brdf.fs)
- [PBR Book 8.4 Microfacet Models](https://www.pbr-book.org/3ed-2018/Reflection_Models/Microfacet_Models)
- [PBR Book 5.6.1 The BRDF](https://www.pbr-book.org/3ed-2018/Color_and_Radiometry/Surface_Reflection#TheBRDF)
- [learnopengl.com PBR Part I "Theory"](https://learnopengl.com/PBR/Theory)
- [Sampling microfacet BRDF](https://agraphicsguy.wordpress.com/2015/11/01/sampling-microfacet-brdf/)
- [Notes On Importance Sampling](https://blog.tobias-franke.eu/2014/03/30/notes_on_importance_sampling.html)
- [Correct Specular Term of the Cook-Torrance / Torrance-Sparrow Model](https://computergraphics.stackexchange.com/questions/3946/correct-specular-term-of-the-cook-torrance-torrance-sparrow-model)
- [Microfacet Distribution Function: To Change or Not to Change, That Is the Question](https://www.scitepress.org/Papers/2021/102527/102527.pdf)
- [Physically Based Shading at Disney](https://media.disneyanimation.com/uploads/production/publication_asset/48/asset/s2012_pbs_disney_brdf_notes_v3.pdf)
- [](https://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdf)
- [](https://blog.selfshadow.com/publications/s2015-shading-course/burley/s2015_pbs_disney_bsdf_slides.pdf)
- [](https://jcgt.org/published/0003/02/03/paper.pdf)